{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree as Tree\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "#from stanfordcorenlp import CoreNLPClient\n",
    "import logging\n",
    "import json\n",
    "#import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP(r'C:\\Users\\wangtao\\Documents\\NLP_project\\stanford-corenlp-full-2018-10-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debugger \n",
    "\n",
    "#import pysnooper\n",
    "\n",
    "# use pysnopper to debug\n",
    "# use @pysnooper.snoop() as decorator\n",
    "# @pysnooper.snoop()\n",
    "# def number_to_bits(number):\n",
    "#Show snoop lines for functions that your function calls:\n",
    "#@pysnooper.snoop(depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sentences:\n",
    "#sentence = \"what is john's average\"\n",
    "#sentence = 'between John Marry Joe what is the average score of them in exam2?'\n",
    "#sentence = 'of thoes who got hihger than 80  what is the average score ?'\n",
    "#sentence = 'what is the average score of thoes who got higher than 80?'\n",
    "#sentence = 'for who got higher than 80 what is the average score?'\n",
    "#sentence = 'For who got higher than 80 in the exams what is the average score of them in exam2?'\n",
    "#sentence = 'What is their average score in exam2 of thoes who got higher than 80 in exam1'\n",
    "#sentence = 'what is the average of exam2 for thoes who got higer than 80 in the exams'\n",
    "#sentence = 'in exam1, who is the higheset?'\n",
    "#sentence = 'for those who pass the exams who is the best?'\n",
    "#sentence = \"who is the best for thoes who passed the exams\"\n",
    "#sentence = 'On assignment1 assignment2 assignment3 which has the higheset average score'\n",
    "#sentence = 'among assignment1 assigment2 assighment3 which has the highest score'\n",
    "#sentence = 'among all of the assignments which has the highest score'\n",
    "#sentence = 'for those who pass the exams what is the average of thoes who are higher than 80'\n",
    "#print (tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "a and b\n",
      "['for who got higher than 80', 'what is the average score']\n"
     ]
    }
   ],
   "source": [
    "# in filter_1  find the structure of pp that contains a clause to justify whether it is a complex sentence\n",
    "tree = Tree.fromstring(str(nlp.parse(sentence)))\n",
    "tags = nlp.pos_tag(sentence)\n",
    "\n",
    "def detect_p (tree):\n",
    "    child_nodes = [child.label() for child in tree.subtrees() if isinstance(child, nltk.Tree)]\n",
    "    #if (tree.label() == 'SBARQ') and ('WHPP' in child_nodes):\n",
    "    return (tree.label()=='PP') and ('SBAR' in child_nodes)\n",
    "    # detect the sturcture \n",
    "\n",
    "def detect_s(tree):\n",
    "    child_nodes = [child.label() for child in tree.subtrees() if isinstance(child, nltk.Tree)]\n",
    "    return (tree.label()=='SBARQ') and ('SBAR' in child_nodes)\n",
    "\n",
    "# extract the sentence\n",
    "def extract_sbar(tree):\n",
    "    child_nodes = [child.label() for child in tree.subtrees() if isinstance(child, nltk.Tree)]\n",
    "    #if (tree.label() == 'SBARQ') and ('WHPP' in child_nodes):\n",
    "    return (tree.label()=='SBAR') and ('S'in child_nodes)\n",
    "\n",
    "def split_pp(sentence):\n",
    "    grammar = r\"\"\"P_CLAUSE:{<IN><DT>?<NN.*|PRP>?<W.*|NN.*><VB.*><JJ.*>?<IN|TO>?<NN.*|PRP|CD>?<IN|TO>?<NN.*|PRP|CD>?}\n",
    "                  PP:{<IN|TO><NN.*|PRP|CD>}\n",
    "                  CLAUSE:{<W.*><VB.*><DT|PRP.*>?<JJ.*>?<NN.*|PRP|CD><PP>?}\"\"\"\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    p = cp.parse(tags)\n",
    "    chunks = []\n",
    "    for subtree in p.subtrees(filter=lambda t: t.label() == 'P_CLAUSE'):\n",
    "        chunk = \"\"\n",
    "        for leave in subtree.leaves():\n",
    "            chunk += leave[0] + ' '\n",
    "            chunks.append(chunk.strip())\n",
    "    return chunks[-1]\n",
    "\n",
    "def split_s(sentence):\n",
    "    grammar = r\"\"\"PP:{<IN|TO><NN.*|PRP|CD>}\n",
    "                CLAUSE:{<W.*><VB.*><DT|PRP.*>?<JJ.*>?<NN.*|PRP|CD><PP>+}\"\"\"\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    p = cp.parse(tags)\n",
    "    chunks = []\n",
    "    for subtree in p.subtrees(filter=lambda t: t.label() == 'CLAUSE'):\n",
    "        chunk = \"\"\n",
    "        for leave in subtree.leaves():\n",
    "            chunk += leave[0] + ' '\n",
    "            chunks.append(chunk.strip())\n",
    "    return chunks[-1]\n",
    "#print(split_s(c))        \n",
    "\n",
    "\n",
    "def is_complex(tree):\n",
    "    wh_list = [\"what\",\"which\",\"who\",\"how\"]\n",
    "    in_list = [\"for\",\"in\",\"at\",\"on\",\"among\",\"to\",\"above\",\"below\",\"between\",\"after\",\"before\"]\n",
    "    b = [t for t in tree.subtrees(filter = detect_s)]\n",
    "    a = [t for t in tree.subtrees(filter = detect_p)]\n",
    "    print(len(a))\n",
    "    if a and b:\n",
    "        print(\"a and b\")\n",
    "        n = len(a)\n",
    "        b1 = b[0].leaves()\n",
    "        if n==2:\n",
    "            if ',' in b1:\n",
    "                ss = sentence.split(',')\n",
    "                return ss\n",
    "            else:\n",
    "                if b1[0] in wh_list:\n",
    "                    b2 = [t.leaves() for t in b[0].subtrees(filter = detect_p)][-1]\n",
    "                    i = -len(b2)\n",
    "                    return [' '.join(e1[0:i]),' '.join(b2)]\n",
    "                if b1[0] in in_list:\n",
    "                    b2 = [t.leaves() for t in b[0].subtrees(filter = extract_sbar)][-1]\n",
    "                    i = -len(b2)\n",
    "                    return [' '.join(b1[0:i-1]),' '.join(b2)]\n",
    "        \n",
    "        if n==1 and b1[0] in in_list:\n",
    "            b2 = [t.leaves() for t in b[0].subtrees(filter = extract_sbar)][0]\n",
    "            i = -len(b2)\n",
    "            return [' '.join(b1[0:i-1]),' '.join(b2)]\n",
    "        if n==1 and b1[0]in wh_list:\n",
    "            b2 = [t.leaves() for t in b[0].subtrees(filter = detect_p)][0]\n",
    "            i = -len(b2)\n",
    "            return [' '.join(b1[0:i]),' '.join(b2)]\n",
    "            \n",
    "    if b and not a:\n",
    "        print(\"only b\")\n",
    "        if ',' in e1:\n",
    "            ss = sentence.split(',')\n",
    "            return ss\n",
    "        else:\n",
    "            e = [t.leaves() for t in b[0].subtrees(filter = detect_p)]\n",
    "        #e = split_pp(sentence)\n",
    "            p = split_s(sentence)\n",
    "        #return[e,p]\n",
    "            return [' '.join(e[0]),p]  \n",
    "    \n",
    "    if a and not b:\n",
    "        print(\"only a\")\n",
    "        n = len(a)\n",
    "        a1 = a[0].leaves()\n",
    "        if n==2:\n",
    "            if ',' in a1:\n",
    "                ss = sentence.split(',')\n",
    "                return ss\n",
    "            else:\n",
    "                if a1[0] in wh_list:\n",
    "                    e = [t.leaves() for t in a[0].subtrees(filter = extract_sbar)]\n",
    "                    p = split_pp(sentence)\n",
    "                    return [' '.join(e[1]),p]\n",
    "                if a1[0] in in_list:\n",
    "                    e = [t.leaves() for t in a[0].subtrees(filter = detect_p)]\n",
    "                    p = split_s(sentence)\n",
    "                    return [' '.join(e[-1]),p]\n",
    "                \n",
    "        if n==1 :\n",
    "            try:\n",
    "                if a1[0] in wh_list:\n",
    "                    e = [t.leaves() for t in tree.subtrees(filter = extract_sbar)]\n",
    "                    p = split_pp(sentence)\n",
    "                    return [' '.join(e[-1]),p] \n",
    "                \n",
    "                if a1[0] in in_list:\n",
    "                    e = [t.leaves() for t in a[0].subtrees(filter = detect_p)]\n",
    "                    s = split_s(sentence)\n",
    "                    return [s,' '.join(e[-1])]\n",
    "            except:\n",
    "                e = [t.leaves() for t in a[0].subtrees() if t.label()==\"SBAR\"]\n",
    "                i = -len(e[0])\n",
    "\n",
    "                return [' '.join(e[0]),' '.join(a1[0:i])]                \n",
    "    else:\n",
    "        return [sentence,'simple']\n",
    "print(is_complex(tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'the', 'average', 'score', 'of', 'them', 'in', 'exam2']]\n"
     ]
    }
   ],
   "source": [
    "a = [t.leaves() for t in tree.subtrees(filter = extract_sbar)]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (SBARQ\n",
      "    (WHNP (WP what))\n",
      "    (SQ\n",
      "      (VBZ is)\n",
      "      (NP\n",
      "        (NP (DT the) (JJ average) (NN score))\n",
      "        (PP\n",
      "          (IN of)\n",
      "          (NP\n",
      "            (NP (NNS thoes))\n",
      "            (SBAR\n",
      "              (WHNP (WP who))\n",
      "              (S\n",
      "                (VP\n",
      "                  (VBD got)\n",
      "                  (NP (JJR higher))\n",
      "                  (PP (IN than) (NP (CD 80))))))))))\n",
      "    (. ?)))\n"
     ]
    }
   ],
   "source": [
    "#print(f)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PP between/IN John/NNP Marry/NNP Joe/NNP)\n",
      "  (CLAUSE\n",
      "    what/WP\n",
      "    is/VBZ\n",
      "    the/DT\n",
      "    average/JJ\n",
      "    score/NN\n",
      "    (PP of/IN them/PRP)\n",
      "    (PP in/IN exam2/NN))\n",
      "  ?/.)\n"
     ]
    }
   ],
   "source": [
    "sentence1 = 'between John Marry Joe what is the average score of them in exam2?'\n",
    "sentence2 = 'What is their average score in exam2 of thoes who got higher than 80 in exam1'\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence1)\n",
    "tags2 = nltk.pos_tag(tokens)\n",
    "\n",
    "grammar = r\"\"\"P_CLAUSE:{<IN><DT>?<JJ.*>?<NN.*|PRP|CD>?<W.*|NN.*><VB.*><JJ.*>?<IN|TO><NN.*|PRP|CD><IN|TO>?<NN.*|PRP|CD>?}\n",
    "PP:{<IN|TO><DT>?<NN.*|PRP|CD>+}\n",
    "CLAUSE:{<W.*><VB.*><DT|PRP.*>?<JJ.*>?<NN.*|PRP|CD><PP>+}\"\"\"\n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "p = cp.parse(tags2)\n",
    "chunks = []\n",
    "for subtree in p.subtrees(filter=lambda t: t.label() == 'P_CLAUSE'):\n",
    "    chunk = \"\"\n",
    "    for leave in subtree.leaves():\n",
    "        chunk += leave[0] + ' '\n",
    "        chunks.append(chunk.strip())\n",
    "\n",
    "print(p)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The detector of representation mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corefs(js):\n",
    "#print(b['sentences'][0][\"entitymentions\"])\n",
    "#print(b['corefs'])\n",
    "n = int(max(js['corefs'].keys()))\n",
    "for i in range (0,n):\n",
    "    i = str(i+1)\n",
    "    #print(js['corefs'][i])\n",
    "    a = js['corefs'][i]\n",
    "    if a[0]['isRepresentativeMention']== True and a[0]['animacy']=='ANIMATE':\n",
    "        #print(a[0]['text'])\n",
    "        return a[0][\"text\"]\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ROOT': ('ROOT', 'exam1')}, {'case': ('exam1', 'in')}, {'punct': ('exam1', ',')}, {'nsubj': ('higheset', 'who')}, {'cop': ('higheset', 'is')}, {'det': ('higheset', 'the')}, {'acl:relcl': ('exam1', 'higheset')}, {'punct': ('exam1', '?')}]\n"
     ]
    }
   ],
   "source": [
    "def depparse_dlist (sentence,list1=None, list2 = None):\n",
    "    list1 = []\n",
    "    #list2 = []\n",
    "    a = js['sentences'][0][\"basicDependencies\"]\n",
    "    for e in a:\n",
    "        dic1 = {e['dep']:(e['governorGloss'],e['dependentGloss'])}\n",
    "        list1.append(dic1)\n",
    "        #dic2 = {e['governorGloss']:e['dependentGloss']}\n",
    "        #list2.append(dic2) \n",
    "    #return list(zip(list1,list2))\n",
    "    return list1\n",
    "\n",
    "print(depparse_dlist(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ROOT', ['On', 'assignment1', 'assignment2', 'assignment3', 'which', 'has', 'the', 'higheset', 'average', 'score']), ('PP', ['On', 'assignment1', 'assignment2', 'assignment3', 'which', 'has', 'the', 'higheset', 'average', 'score']), ('IN', ['On']), ('NP', ['assignment1', 'assignment2', 'assignment3', 'which', 'has', 'the', 'higheset', 'average', 'score']), ('NP', ['assignment1', 'assignment2', 'assignment3']), ('NN', ['assignment1']), ('NN', ['assignment2']), ('NN', ['assignment3']), ('SBAR', ['which', 'has', 'the', 'higheset', 'average', 'score']), ('WHNP', ['which']), ('WDT', ['which']), ('S', ['has', 'the', 'higheset', 'average', 'score']), ('VP', ['has', 'the', 'higheset', 'average', 'score']), ('VBZ', ['has']), ('NP', ['the', 'higheset', 'average', 'score']), ('DT', ['the']), ('JJ', ['higheset']), ('JJ', ['average']), ('NN', ['score'])]\n"
     ]
    }
   ],
   "source": [
    "print([(t.label(),t.leaves()) for t in tree.subtrees()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ROOT', 'SBARQ', 'WHPP', 'IN', 'WHNP', 'WP', 'SQ', 'VP', 'VBD', 'NP', 'JJR', 'PP', 'IN', 'NP', 'NP', 'CD', 'SBAR', 'WHNP', 'WP', 'S', 'VP', 'VBZ', 'NP', 'DT', 'JJ', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "#print([subtree.label() for subtree in tree.subtrees()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['WHPP', 'SQ', '.'], ['For who', 'got higher than 80 in the exams what is the average score of them in exam2', '?'])\n"
     ]
    }
   ],
   "source": [
    "def get_top_level_structure(tree):\n",
    "    top_level_structure = []\n",
    "    parse_by_structure = []\n",
    "    for t in tree[0]:\n",
    "        if t.label() == \"PP\":\n",
    "            parse_by_structure += get_VB(t)\n",
    "            top_level_structure += [\"VB\", \"OTHER\"]\n",
    "        else:\n",
    "            parse_by_structure.append(\" \".join(t.leaves()))\n",
    "            top_level_structure.append(t.label())\n",
    "    return (top_level_structure, parse_by_structure)\n",
    "        \n",
    "print(get_top_level_structure(tree))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
